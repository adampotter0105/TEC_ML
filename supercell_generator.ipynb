{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae03e7493c58d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T20:55:36.420725500Z",
     "start_time": "2023-11-20T20:55:36.408708600Z"
    }
   },
   "outputs": [],
   "source": [
    "from ase.io import read, write\n",
    "from ase.build import make_supercell\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T20:55:36.768465500Z",
     "start_time": "2023-11-20T20:55:36.752957900Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_supercells(cif_files, input_dir, output_dir, meta_filename, N_MAX=4, verbose=False, debug=False, mat_class=\"oxide\"):\n",
    "    # Convert Each CIF File (lots of gross text processing, beware!)\n",
    "    dead_files = 0  # Files with no data\n",
    "    for f in cif_files:\n",
    "        f_name = str(int(float(f.split('.cif')[0]))) # some files have a '.0' we should remove\n",
    "        meta_data = list()\n",
    "        if verbose: \n",
    "            print(\"Name: \", f_name)\n",
    "        # Alter some formatting to make the file load better into ASE, copy into output folder\n",
    "        occupation = dict()  # For each site, what elements exist and how many\n",
    "        site_tag_dict = dict()  # Dict with element tags and site name values\n",
    "        # We replace the actual element with one of these so we can find the site later\n",
    "        site_tags = ['H','He','Li','Be','B','C','N','O','F','Ne',  \n",
    "                     'Na','Mg','Al','Si','P','S','Cl','Ar','K', 'Ca',\n",
    "                     'Sc', 'Ti', 'V','Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
    "                     'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',\n",
    "                     'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru',\n",
    "                     'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te',\n",
    "                     'I', 'Xe','Cs', 'Ba','La', 'Ce', 'Pr', 'Nd', 'Pm',\n",
    "                     'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm',\n",
    "                     'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir',\n",
    "                     'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn',\n",
    "                     'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am',\n",
    "                     'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr',\n",
    "                     'Rf', 'Db', 'Sg', 'Bh','Hs', 'Mt', 'Ds', 'Rg', 'Cn',\n",
    "                     'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og']\n",
    "        for k in range(2,7):  # Make it extra long\n",
    "            site_tags += [k*i for i in site_tags]\n",
    "        if verbose:\n",
    "            print(len(site_tags))\n",
    "\n",
    "        with open(input_dir+f, \"r\") as file:\n",
    "            contents = file.read().split('\\n')\n",
    "            fh  = open(output_dir+f, 'w') # Re-saves a better formatted file\n",
    "            format_start = False\n",
    "            write_start = False\n",
    "            num_loops = 0  # number of times '_loop' is seen\n",
    "            data_lookup = dict()\n",
    "            meta_data.append({\"structure\": f_name, \"material_class\": mat_class})\n",
    "            for line in contents:\n",
    "                # Record Occupation\n",
    "                if num_loops>=2 and len(line)>1 and '#' not in line:  # Data stored in second _loop\n",
    "                   if line[1] == '_':  # Add to data labels \n",
    "                        data_lookup[line] = len(data_lookup)  # Index for that data label\n",
    "                   elif len(line.split()) > 4 :  # Data probably listed\n",
    "                       spl = line.split()\n",
    "                       try:\n",
    "                           site_label = spl[data_lookup[' _atom_site_fract_x']] + \" \" + spl[data_lookup[' _atom_site_fract_y']] + \" \" + spl[data_lookup[' _atom_site_fract_z']] \n",
    "                       except: raise Exception(\"NO SITE DESCRIPTORS FOUND\")\n",
    "                        \n",
    "                       if site_label not in occupation.keys():\n",
    "                            occupation[site_label] = {}\n",
    "                            tag = site_tags[len(site_tag_dict)]\n",
    "                            site_tag_dict[tag] = site_label  # Remember this site is a given element tag\n",
    "                       else:\n",
    "                           tag = list(site_tag_dict.keys())[list(site_tag_dict.values()).index(site_label)]\n",
    "                       #  Add element occupancy to\n",
    "                       if ' _atom_site_occupancy' in data_lookup.keys():\n",
    "                           occupation[site_label][spl[data_lookup[' _atom_site_type_symbol']]] = float(spl[data_lookup[' _atom_site_occupancy']])\n",
    "                       else:  # No element occupancy data found\n",
    "                           occupation[site_label][spl[data_lookup[' _atom_site_type_symbol']]] = 1\n",
    "                        \n",
    "                       spl[data_lookup[' _atom_site_type_symbol']] = tag  # Replace real element with tag\n",
    "                       line = ' '+'\\t'.join(spl)\n",
    "               # Format\n",
    "                if len(line)<1:  # End formatting\n",
    "                    format_start = False\n",
    "                if 'data' in line or '_cell' in line:\n",
    "                    write_start = True\n",
    "                # Copy Over text\n",
    "                if format_start and \"'\" not in line:\n",
    "                    spl = line.split()\n",
    "                    fh.write(spl[0]+\" '\"+' '.join(spl[1:])+\"' \\n\")\n",
    "                elif write_start:\n",
    "                    fh.write(line+'\\n')\n",
    "                if '_symmetry_equiv_pos_as_xyz' in line:\n",
    "                    format_start = True\n",
    "                if 'loop_' in line:\n",
    "                    num_loops += 1\n",
    "                    \n",
    "                # Record meta data\n",
    "                if 'symmetry_Int_Tables_number' in line: \n",
    "                    meta_data[-1][\"symmetry_int_table_number\"] = line.split()[1]\n",
    "                elif '_symmetry_space_group_name_H-M' in line:\n",
    "                    meta_data[-1][\"space_goup\"] = line.split()[1]\n",
    "                elif '_space_group_crystal_system' in line:\n",
    "                    meta_data[-1][\"crystal_system\"] = line.split()[1]\n",
    "\n",
    "            fh.close()    \n",
    "            file.close()\n",
    "            \n",
    "        # Find the numer of elements\n",
    "        elements = set()\n",
    "        for k in occupation:\n",
    "            for p in occupation[k]:\n",
    "                elements.add(p)\n",
    "        num_elements = len(elements)\n",
    "        meta_data[-1][\"num_elements\"] = num_elements\n",
    "        if num_elements <= 2:\n",
    "            meta_data[-1][\"composition_class\"] = \"binary\"\n",
    "        elif num_elements <= 5:\n",
    "            meta_data[-1][\"composition_class\"] = \"ternary-quinary\"\n",
    "        else:\n",
    "            meta_data[-1][\"composition_class\"] = \"high-entropy\"\n",
    "        \n",
    "        # Throw error if file is empty and skip \n",
    "        if len(occupation) < 1:\n",
    "            if verbose: \n",
    "                print(\"NO DATA FOUND FOR: \", f, \"! Skipping...\")\n",
    "            dead_files += 1\n",
    "            continue\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"Occupation: \", occupation)\n",
    "        # Load the original CIF file\n",
    "        if debug:  \n",
    "            with(open(output_dir+f, \"r\") as file):\n",
    "                contents = file.read().split('\\n')\n",
    "                for line in contents:\n",
    "                    print(line)\n",
    "            file.close()\n",
    "            \n",
    "        original_structure = read(output_dir+f) # Open formatted file copied into output dir\n",
    "        \n",
    "        # Define the supercell size adaptively\n",
    "        # Find minimum element fraction for any given element\n",
    "        x_min = 1\n",
    "        for k1 in occupation.values():\n",
    "            for k2 in k1.values():\n",
    "                x_min = min(k2, x_min)\n",
    "        n = np.ceil((5/x_min)**(1/3))  # Adaptive cell size to be <10% element representation error\n",
    "        if x_min == 1:  # Use base cell if no mixed occupation lattice site\n",
    "            supercell_dim = 1  # necessary for polyhedra featurizing in feature_generator.ipynb\n",
    "        else:\n",
    "            supercell_dim = min(n, N_MAX)  # Use a big enough supercell to limit representative error, max size N_MAX\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Supercell dim: \", supercell_dim)\n",
    "        supercell_size = supercell_dim*np.eye(3) \n",
    "                \n",
    "        # Create the supercell\n",
    "        superlattice = make_supercell(original_structure, supercell_size)\n",
    "        \n",
    "        # Keep track of where each atom is in the superlattice\n",
    "        site_list = list() # which site is at each atomic location in superlattice\n",
    "        site_count = dict() # how many site of each exist\n",
    "        for k in occupation.keys():\n",
    "            site_count[k] = 0\n",
    "        for atom in range(len(superlattice)):\n",
    "            tag = superlattice[atom].symbol  # Name of tag element\n",
    "            site = site_tag_dict[tag]  # Name of site this represents\n",
    "            site_list.append(site)\n",
    "            site_count[site] += 1\n",
    "\n",
    "        if len(site_list) != len(superlattice):\n",
    "            print(site_list)\n",
    "            print(superlattice)\n",
    "            raise Exception(\"Not every atom in super-lattice accounted for in occupation dictionary!\")\n",
    "        \n",
    "        # Create list of atoms to draw from for each site\n",
    "        site_sampler = dict()\n",
    "        for site in occupation.keys():\n",
    "            site_sampler[site] = list()\n",
    "            # Make representative list of atoms to draw from\n",
    "            for atom in occupation[site].keys():\n",
    "                n_atoms = round( occupation[site][atom]*site_count[site] )\n",
    "                site_sampler[site] = site_sampler[site] + [atom]*n_atoms\n",
    "            # List too long, pop random element\n",
    "            while len(site_sampler[site]) > site_count[site]: \n",
    "                random.shuffle(site_sampler[site])\n",
    "                site_sampler[site].pop()\n",
    "            # List too short, fill with vacancies\n",
    "            while len(site_sampler[site]) < site_count[site]:\n",
    "                site_sampler[site].append('')\n",
    "    \n",
    "        # Replace atoms based on occupation fraction\n",
    "        vacancies = list()\n",
    "        # Shuffle each site in the sampler dictionary\n",
    "        for site in occupation.keys():\n",
    "            random.shuffle(site_sampler[site])\n",
    "        # For every atom in the lattice, draw an element to replace the atom with\n",
    "        for atom in range(len(superlattice)):\n",
    "            atom_site = site_list[atom]\n",
    "            element_draw = site_sampler[atom_site][0]\n",
    "            del site_sampler[atom_site][0]\n",
    "            if element_draw == \"\":\n",
    "                vacancies.append(atom)\n",
    "            else:\n",
    "                superlattice[atom].symbol = element_draw\n",
    "        # Create oxygen vacancies in lattice by deletion\n",
    "        for i in range(len(vacancies)):\n",
    "            del superlattice[vacancies[i]-i]\n",
    "   \n",
    "        # Save the superlattice structure in a new CIF file\n",
    "        write(output_dir+f_name+'_super.cif', superlattice)\n",
    "        \n",
    "        # Save meta data\n",
    "        file_exists = os.path.isfile(meta_filename)\n",
    "        with open(meta_filename, 'a') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=list(meta_data[0].keys()))\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            writer.writerows(meta_data)\n",
    "        \n",
    "    print(\"Number of dead files: \", dead_files)\n",
    "    print(\"Finished: processed \"+ str(len(cif_files)) +\" files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1047e995e5d5d48a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T20:55:49.049993Z",
     "start_time": "2023-11-20T20:55:43.920124100Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dead files:  100\n",
      "Finished: processed 671 files\n",
      "Number of dead files:  18\n",
      "Finished: processed 177 files\n",
      "Number of dead files:  0\n",
      "Finished: processed 32 files\n",
      "Number of dead files:  1\n",
      "Finished: processed 33 files\n"
     ]
    }
   ],
   "source": [
    "## Script Parameters\n",
    "input_dirs = [\"oxide_linear/\", \"oxide_volume/\", \"fluoride_linear/\", \"fluoride_volume/\"]  # CIF files source directories\n",
    "output_dir = \"supercells_data/\"  # CIF supercell output file directory\n",
    "\n",
    "meta_data_filename = \"features/cif_metadata.csv\"\n",
    "if os.path.exists(meta_data_filename): # If file already exists, delete it\n",
    "    os.remove(meta_data_filename)\n",
    "\n",
    "for input_dir in input_dirs:\n",
    "    # Load all CIF files in\n",
    "    file_type = \".cif\"\n",
    "    files = os.listdir(input_dir)\n",
    "    cif_files = [file for file in files if file.endswith(file_type)]\n",
    "\n",
    "    # Supercell max dimension\n",
    "    N_MAX = 4  # maximum size allowed for supercell (NxNxN unit cells)\n",
    "\n",
    "    # Make Output Directory if needed\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    # Atom('O', [27.765269999999994, 34.01027, 9.945936], index=1231)\n",
    "    if 'fluoride' in input_dir:\n",
    "        mat_class = \"fluoride\"\n",
    "    else:\n",
    "        mat_class = \"oxide\"\n",
    "    generate_supercells(cif_files, input_dir, output_dir, meta_data_filename, N_MAX=N_MAX, verbose=False, mat_class=mat_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a35f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

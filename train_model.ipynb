{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:43:31.727156300Z",
     "start_time": "2023-11-20T20:43:25.391539100Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:13<00:00, 1903269.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 196796.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:02<00:00, 1726460.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:43:51.391369300Z",
     "start_time": "2023-11-20T20:43:31.727156300Z"
    }
   },
   "id": "bc3805e90b17a7ed"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cbook' has no attribute '_safe_first_finite'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Create a grid from the images and show them\u001B[39;00m\n\u001B[0;32m     16\u001B[0m img_grid \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mmake_grid(images)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mmatplotlib_imshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_grid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mone_channel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(classes[labels[j]] \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m4\u001B[39m)))\n",
      "Cell \u001B[1;32mIn[3], line 8\u001B[0m, in \u001B[0;36mmatplotlib_imshow\u001B[1;34m(img, one_channel)\u001B[0m\n\u001B[0;32m      6\u001B[0m npimg \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m one_channel:\n\u001B[1;32m----> 8\u001B[0m     \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnpimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGreys\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     10\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimshow(np\u001B[38;5;241m.\u001B[39mtranspose(npimg, (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m)))\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:3346\u001B[0m, in \u001B[0;36mimshow\u001B[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[0;32m   3325\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[0;32m   3326\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[0;32m   3327\u001B[0m     X: ArrayLike \u001B[38;5;241m|\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3344\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3345\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AxesImage:\n\u001B[1;32m-> 3346\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mimshow(\n\u001B[0;32m   3347\u001B[0m         X,\n\u001B[0;32m   3348\u001B[0m         cmap\u001B[38;5;241m=\u001B[39mcmap,\n\u001B[0;32m   3349\u001B[0m         norm\u001B[38;5;241m=\u001B[39mnorm,\n\u001B[0;32m   3350\u001B[0m         aspect\u001B[38;5;241m=\u001B[39maspect,\n\u001B[0;32m   3351\u001B[0m         interpolation\u001B[38;5;241m=\u001B[39minterpolation,\n\u001B[0;32m   3352\u001B[0m         alpha\u001B[38;5;241m=\u001B[39malpha,\n\u001B[0;32m   3353\u001B[0m         vmin\u001B[38;5;241m=\u001B[39mvmin,\n\u001B[0;32m   3354\u001B[0m         vmax\u001B[38;5;241m=\u001B[39mvmax,\n\u001B[0;32m   3355\u001B[0m         origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[0;32m   3356\u001B[0m         extent\u001B[38;5;241m=\u001B[39mextent,\n\u001B[0;32m   3357\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[0;32m   3358\u001B[0m         filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[0;32m   3359\u001B[0m         filterrad\u001B[38;5;241m=\u001B[39mfilterrad,\n\u001B[0;32m   3360\u001B[0m         resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[0;32m   3361\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   3362\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m   3363\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3364\u001B[0m     )\n\u001B[0;32m   3365\u001B[0m     sci(__ret)\n\u001B[0;32m   3366\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:2528\u001B[0m, in \u001B[0;36mgca\u001B[1;34m()\u001B[0m\n\u001B[0;32m   2526\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Figure\u001B[38;5;241m.\u001B[39mgca)\n\u001B[0;32m   2527\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgca\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Axes:\n\u001B[1;32m-> 2528\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgcf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:1658\u001B[0m, in \u001B[0;36mFigureBase.gca\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1648\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m \u001B[38;5;124;03mGet the current Axes.\u001B[39;00m\n\u001B[0;32m   1650\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1655\u001B[0m \u001B[38;5;124;03mwhether `.pyplot.get_fignums()` is empty.)\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1657\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_axstack\u001B[38;5;241m.\u001B[39mcurrent()\n\u001B[1;32m-> 1658\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ax \u001B[38;5;28;01mif\u001B[39;00m ax \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_subplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:782\u001B[0m, in \u001B[0;36mFigureBase.add_subplot\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    780\u001B[0m         args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m(args[\u001B[38;5;241m0\u001B[39m])))\n\u001B[0;32m    781\u001B[0m     projection_class, pkw \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_projection_requirements(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 782\u001B[0m     ax \u001B[38;5;241m=\u001B[39m projection_class(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpkw)\n\u001B[0;32m    783\u001B[0m     key \u001B[38;5;241m=\u001B[39m (projection_class, pkw)\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_add_axes_internal(ax, key)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:678\u001B[0m, in \u001B[0;36m_AxesBase.__init__\u001B[1;34m(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, *args, **kwargs)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_axisbelow(mpl\u001B[38;5;241m.\u001B[39mrcParams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxes.axisbelow\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rasterization_zorder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 678\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclear\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    680\u001B[0m \u001B[38;5;66;03m# funcs used to format x and y - fall back on major formatters\u001B[39;00m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt_xdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:1388\u001B[0m, in \u001B[0;36m_AxesBase.clear\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1386\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcla()\n\u001B[0;32m   1387\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1388\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__clear\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:1376\u001B[0m, in \u001B[0;36m_AxesBase.__clear\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1374\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpolar\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1375\u001B[0m             axis\u001B[38;5;241m.\u001B[39m_set_scale(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1376\u001B[0m         \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_lim\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_transScale()\n\u001B[0;32m   1379\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py:1209\u001B[0m, in \u001B[0;36mAxis._set_lim\u001B[1;34m(self, v0, v1, emit, auto)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;124;03mSet view limits.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1205\u001B[0m \u001B[38;5;124;03m    turns off, None leaves unchanged.\u001B[39;00m\n\u001B[0;32m   1206\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1207\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_axis_name()\n\u001B[1;32m-> 1209\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maxes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_unit_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mv0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv1\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1210\u001B[0m v0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39m_validate_converted_limits(v0, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_units)\n\u001B[0;32m   1211\u001B[0m v1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39m_validate_converted_limits(v1, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_units)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:2555\u001B[0m, in \u001B[0;36m_AxesBase._process_unit_info\u001B[1;34m(self, datasets, kwargs, convert)\u001B[0m\n\u001B[0;32m   2553\u001B[0m     \u001B[38;5;66;03m# Update from data if axis is already set but no unit is set yet.\u001B[39;00m\n\u001B[0;32m   2554\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m axis\u001B[38;5;241m.\u001B[39mhave_units():\n\u001B[1;32m-> 2555\u001B[0m         \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_units\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2556\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis_name, axis \u001B[38;5;129;01min\u001B[39;00m axis_map\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   2557\u001B[0m     \u001B[38;5;66;03m# Return if no axis is set.\u001B[39;00m\n\u001B[0;32m   2558\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py:1706\u001B[0m, in \u001B[0;36mAxis.update_units\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1700\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_units\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[0;32m   1701\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;124;03m    Introspect *data* for units converter and update the\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;124;03m    ``axis.converter`` instance if necessary. Return *True*\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;124;03m    if *data* is registered for unit conversion.\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1706\u001B[0m     converter \u001B[38;5;241m=\u001B[39m \u001B[43mmunits\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_converter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1707\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1708\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\units.py:183\u001B[0m, in \u001B[0;36mRegistry.get_converter\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    181\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:  \u001B[38;5;66;03m# If cache lookup fails, look up based on first element...\u001B[39;00m\n\u001B[1;32m--> 183\u001B[0m     first \u001B[38;5;241m=\u001B[39m \u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_safe_first_finite\u001B[49m(x)\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mStopIteration\u001B[39;00m):\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\__init__.py:217\u001B[0m, in \u001B[0;36mcaching_module_getattr.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m props:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m props[name]\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance)\n\u001B[1;32m--> 217\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__module__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'matplotlib.cbook' has no attribute '_safe_first_finite'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:43:53.688426900Z",
     "start_time": "2023-11-20T20:43:51.391369300Z"
    }
   },
   "id": "c4d40abaf6e6581a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:44:28.910232500Z",
     "start_time": "2023-11-20T20:44:28.878907Z"
    }
   },
   "id": "6064ae5e0e3b13e1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3132, 0.7210, 0.5673, 0.2654, 0.3235, 0.9224, 0.6202, 0.3625, 0.7469,\n",
      "         0.6825],\n",
      "        [0.2942, 0.6152, 0.1988, 0.7836, 0.4753, 0.6508, 0.2220, 0.6671, 0.8415,\n",
      "         0.1063],\n",
      "        [0.6119, 0.0444, 0.7082, 0.5169, 0.1634, 0.7523, 0.9414, 0.5427, 0.3982,\n",
      "         0.2870],\n",
      "        [0.3223, 0.9421, 0.6929, 0.5717, 0.0364, 0.5114, 0.6255, 0.8528, 0.5490,\n",
      "         0.5728]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.1716437339782715\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:44:30.036898100Z",
     "start_time": "2023-11-20T20:44:30.020849100Z"
    }
   },
   "id": "528dd6769445e6f1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:44:30.610678800Z",
     "start_time": "2023-11-20T20:44:30.596947100Z"
    }
   },
   "id": "35986640c7e85bf5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:44:31.467747500Z",
     "start_time": "2023-11-20T20:44:31.452137500Z"
    }
   },
   "id": "d8991ccb4b258204"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.93683554571867\n",
      "  batch 2000 loss: 0.8742506859395653\n",
      "  batch 3000 loss: 0.695147590004839\n",
      "  batch 4000 loss: 0.6590565515952185\n",
      "  batch 5000 loss: 0.5924664702033624\n",
      "  batch 6000 loss: 0.5554976974700112\n",
      "  batch 7000 loss: 0.5464370773204137\n",
      "  batch 8000 loss: 0.5189417056806851\n",
      "  batch 9000 loss: 0.48867885893536733\n",
      "  batch 10000 loss: 0.5045744359018282\n",
      "  batch 11000 loss: 0.4542827845304273\n",
      "  batch 12000 loss: 0.43265407396911176\n",
      "  batch 13000 loss: 0.42582175541541073\n",
      "  batch 14000 loss: 0.4398292359773186\n",
      "  batch 15000 loss: 0.40503787003926117\n",
      "LOSS train 0.40503787003926117 valid 0.49880170822143555\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.3833599199294695\n",
      "  batch 2000 loss: 0.4106794128913898\n",
      "  batch 3000 loss: 0.3842370055730571\n",
      "  batch 4000 loss: 0.3915839364415733\n",
      "  batch 5000 loss: 0.38678596353169997\n",
      "  batch 6000 loss: 0.37745690111066504\n",
      "  batch 7000 loss: 0.3828030573599099\n",
      "  batch 8000 loss: 0.37208822602033614\n",
      "  batch 9000 loss: 0.3571795850968774\n",
      "  batch 10000 loss: 0.3877112821220653\n",
      "  batch 11000 loss: 0.3737840119041066\n",
      "  batch 12000 loss: 0.35722475111516544\n",
      "  batch 13000 loss: 0.3472358174704277\n",
      "  batch 14000 loss: 0.3599102582920459\n",
      "  batch 15000 loss: 0.33877766022933065\n",
      "LOSS train 0.33877766022933065 valid 0.3942723870277405\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.321615675437497\n",
      "  batch 2000 loss: 0.34199783817253776\n",
      "  batch 3000 loss: 0.34156610048512814\n",
      "  batch 4000 loss: 0.3534768680605921\n",
      "  batch 5000 loss: 0.3301340673356317\n",
      "  batch 6000 loss: 0.32557213008825786\n",
      "  batch 7000 loss: 0.332227138219343\n",
      "  batch 8000 loss: 0.31842132463098094\n",
      "  batch 9000 loss: 0.33728194850202997\n",
      "  batch 10000 loss: 0.3350160714922822\n",
      "  batch 11000 loss: 0.3334053547422518\n",
      "  batch 12000 loss: 0.30773435719330156\n",
      "  batch 13000 loss: 0.2989095876806823\n",
      "  batch 14000 loss: 0.3141688510561362\n",
      "  batch 15000 loss: 0.3317895122382033\n",
      "LOSS train 0.3317895122382033 valid 0.32837632298469543\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.3017502097174802\n",
      "  batch 2000 loss: 0.2944527656824712\n",
      "  batch 3000 loss: 0.29431875876584673\n",
      "  batch 4000 loss: 0.3115632609757304\n",
      "  batch 5000 loss: 0.3047618178666744\n",
      "  batch 6000 loss: 0.2943663061873667\n",
      "  batch 7000 loss: 0.315778285435852\n",
      "  batch 8000 loss: 0.3233881073771336\n",
      "  batch 9000 loss: 0.3000496586196107\n",
      "  batch 10000 loss: 0.30582666691602933\n",
      "  batch 11000 loss: 0.286444687574709\n",
      "  batch 12000 loss: 0.30942561077464414\n",
      "  batch 13000 loss: 0.30400190677558203\n",
      "  batch 14000 loss: 0.2988061673989723\n",
      "  batch 15000 loss: 0.3113282083034146\n",
      "LOSS train 0.3113282083034146 valid 0.33228281140327454\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.29300736992470044\n",
      "  batch 2000 loss: 0.27312985402171763\n",
      "  batch 3000 loss: 0.28514522292471883\n",
      "  batch 4000 loss: 0.27380759825190765\n",
      "  batch 5000 loss: 0.2909198896391481\n",
      "  batch 6000 loss: 0.2972945783408868\n",
      "  batch 7000 loss: 0.27323083476845933\n",
      "  batch 8000 loss: 0.2934916789634881\n",
      "  batch 9000 loss: 0.29442609285520305\n",
      "  batch 10000 loss: 0.2724124859930016\n",
      "  batch 11000 loss: 0.29177686745462417\n",
      "  batch 12000 loss: 0.28696662267373174\n",
      "  batch 13000 loss: 0.30615980892871447\n",
      "  batch 14000 loss: 0.26671210415628954\n",
      "  batch 15000 loss: 0.275208879068804\n",
      "LOSS train 0.275208879068804 valid 0.3190481960773468\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                       epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T20:47:38.054780600Z",
     "start_time": "2023-11-20T20:44:32.076829800Z"
    }
   },
   "id": "de4f00a0b39607b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d9dbc1f79cc85b14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
